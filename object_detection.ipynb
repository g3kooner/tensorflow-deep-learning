{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6svNVmk2FVt"
      },
      "source": [
        "## Image Classification with Object Detection\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this colab, we utilize Tensorflows Object Detection API alongside transfer learning to load, customize and retrain the [RetinaNet](https://arxiv.org/abs/1512.03385) model to perform image classification and track rubber duckies with just 5 training examples. We will download the model from the Tensorflow model garden and restore its checkpointed weights with the addition of some fine tuning with our own custom training loop. Lets get started!\n",
        "\n",
        "![ducky](images/ducky.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhXzhANqNnhR"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We will begin by cloning the Tensorflow model garden as well as installing the Tensorflow 2 [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Paci_57LIDIm"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./models/\n",
        "\n",
        "# clone the tensorflow model repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jsJQXHpIcDo"
      },
      "outputs": [],
      "source": [
        "# install the tensorflow object detection API\n",
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4yrbRaEPHCn"
      },
      "source": [
        "**In Google Colab, you will need to restart the runtime to ensure the installation of the packages before. Please select Runtime --> Restart Runtime located in the tool bar above. Do not continue into the next section without restarting otherwise some of the imports will fail.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSOpoxYdPBdn"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Now we will import the necessary modules to perform the task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMN-xh2qI-u8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import imageio\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib.image import imread\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxcpahX1JgNX"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Next we will read the 5 rubber ducky training images and store their NumPy equivalent to pass into our model for training later. Addtionally, we will create the bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn5_u8hjL09J"
      },
      "outputs": [],
      "source": [
        "image_dir = \"/content/models/research/object_detection/test_images/ducky/train\"\n",
        "train_images = []\n",
        "for i in range(1, 6):\n",
        "  image_path = os.path.join(image_dir, 'robertducky' + str(i) + '.jpg')\n",
        "  train_images.append(imread(image_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eEs3sSTSSUf"
      },
      "source": [
        "We will also want to create the approriate bounding boxes for our examples and you can do so by running the cell below. Make sure to draw the box as tight as possible while still containing the entire rubber duck otherwise the model might pick up on some unwanted background features. Dont proceed without bounding all images (5) and only click 'submit' when the 'All images completed!' message appears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEsFzMZlL4QX"
      },
      "outputs": [],
      "source": [
        "bounding_boxes = []\n",
        "colab_utils.annotate(train_images, box_storage_pointer=bounding_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClbbhuK3AIe8"
      },
      "source": [
        "Here we define the category index dictionary which will be used by succeeding functions to match the class_id to the name of the object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HI0SVldL7x-"
      },
      "outputs": [],
      "source": [
        "%%writefile models/research/object_detection/data/ducky_label_map.pbtxt\n",
        "\n",
        "item {\n",
        "  name: \"robertducky\"\n",
        "  id: 1\n",
        "  display_name: \"rubber_ducky\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smkKS7UqfoYN"
      },
      "outputs": [],
      "source": [
        "PATH_TO_LABELS = \"./models/research/object_detection/data/ducky_label_map.pbtxt\"\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQb5loewAYCk"
      },
      "source": [
        "We convert our NumPy data into well structured tensors for input and the  class labels will also need to be one-hot encoded as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVBxl4dLgOMN"
      },
      "outputs": [],
      "source": [
        "train_image_tensors = []\n",
        "bounding_box_tensors = []\n",
        "class_label_tensors = []\n",
        "\n",
        "for (train_image, bounding_box) in zip(train_images, bounding_boxes):\n",
        "  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(train_image, dtype='float32'), axis=0))\n",
        "  bounding_box_tensors.append(tf.convert_to_tensor(bounding_box, dtype='float32'))\n",
        "  zero_indexed_class_labels = tf.convert_to_tensor(np.ones(shape=[bounding_box.shape[0]], dtype=np.int32) - 1)\n",
        "  class_label_tensors.append(tf.one_hot(zero_indexed_class_labels, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLM7bDWyB633"
      },
      "source": [
        "## Visualize the images with bounding boxes\n",
        "\n",
        "By running the following code cell, you should see 5 images with the bounding boxes you drew earlier. If not, please return to the annotation step and re-do the drawing process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx-BtLqMhWMj"
      },
      "outputs": [],
      "source": [
        "train_images_with_boxes = train_images.copy()\n",
        "\n",
        "plt.figure(figsize=(30, 15))\n",
        "for i in range(5):\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      train_images_with_boxes[i],\n",
        "      bounding_boxes[i],\n",
        "      np.ones(shape=(len(train_images)), dtype='int32'),\n",
        "      np.array([1.0], dtype='float32'),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "\n",
        "  plt.imshow(train_images_with_boxes[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7h2aOyBobSJ"
      },
      "source": [
        "## Retreive the model checkpoints and restore weights\n",
        "\n",
        "Now we will download RetinaNet and move it into the object detection directory.\n",
        "\n",
        "We will restore and build everything expect the classification layer at the head thus it will be randomly intialized by default. We will perform fine tuning later on to allow our model to adapt to the specfic task we need it for. For reference, we are using the Resnet 50 V1, 640x640 checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8A9rOm0nN4C"
      },
      "outputs": [],
      "source": [
        "!wget \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\"\n",
        "!tar -xf \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\"\n",
        "!mv \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint\" \"models/research/object_detection/test_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P858ZfPBA7vW"
      },
      "outputs": [],
      "source": [
        "pipeline_config = 'models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
        "checkpoint_path = 'models/research/object_detection/test_data/checkpoint/ckpt-0'\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = config['model']\n",
        "model_config.ssd.freeze_batchnorm = True; model_config.ssd.num_classes = 1\n",
        "\n",
        "resnet_model = model_builder.build(model_config=model_config, is_training=True)\n",
        "\n",
        "temp_box_predictor = tf.compat.v2.train.Checkpoint(\n",
        "    _base_tower_layers_for_heads=resnet_model._box_predictor._base_tower_layers_for_heads,\n",
        "    _box_prediction_head=resnet_model._box_predictor._box_prediction_head\n",
        ")\n",
        "\n",
        "temp_model = tf.compat.v2.train.Checkpoint(\n",
        "    _feature_extractor=resnet_model._feature_extractor,\n",
        "    _box_predictor=temp_box_predictor\n",
        ")\n",
        "\n",
        "checkpoint_path = \"/content/models/research/object_detection/test_data/checkpoint/ckpt-0\"\n",
        "checkpoint = tf.compat.v2.train.Checkpoint(model=temp_model)\n",
        "checkpoint.restore(checkpoint_path).expect_partial()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFxR6fBYIxKX"
      },
      "source": [
        "The short cell below will forward pass a fake image through our instantiated model to create the trainable variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ctv3ZH1tBkqa"
      },
      "outputs": [],
      "source": [
        "image, shape = resnet_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
        "predictions = resnet_model.predict(image, shape)\n",
        "tmp_detections = resnet_model.postprocess(predictions, shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cfoAQLDDyzU"
      },
      "source": [
        "## Fine tuning and custom training loop\n",
        "\n",
        "To take full advantage of transfer learning and pre-trained weights, we will only train the parameters of the prediction layers at the top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OyGNYbEDvGu"
      },
      "outputs": [],
      "source": [
        "fine_tune_vars = []\n",
        "prefixes_to_tune = ['WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
        "                    'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
        "\n",
        "for var in resnet_model.trainable_variables:\n",
        "  if (any([var.name.find(prefix) != -1 for prefix in prefixes_to_tune])):\n",
        "    fine_tune_vars.append(var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUDQcb5zLxKm"
      },
      "source": [
        "The following function defines a training step in which we will provide the model with our ground_truth values, preprocess the images, make a prediction and calculate the following loss. Note the total loss is defined as the addition of the classification and object localization loss. We then use Tensorflows GradientTape for automatic differentiation to fine tune to trainable variables at every step following the SGD optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap7ptzyjFKgu"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def model_train_loop(images, bounding_boxes, class_labels, model, optimizer, fine_tune_vars):\n",
        "  model.provide_groundtruth(\n",
        "      groundtruth_boxes_list=bounding_boxes,\n",
        "      groundtruth_classes_list=class_labels\n",
        "  )\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    preprocess_img_list = []\n",
        "    shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\n",
        "\n",
        "    for image in images: preprocess_img_list.append(model.preprocess(image)[0])\n",
        "\n",
        "    preprocess_img_tensor = tf.concat(preprocess_img_list, axis=0)\n",
        "\n",
        "    predicts = model.predict(preprocess_img_tensor, shapes)\n",
        "    loss = model.loss(predicts, shapes)\n",
        "\n",
        "    total_loss = loss['Loss/localization_loss'] + loss['Loss/classification_loss']\n",
        "    gradients = tape.gradient(total_loss, fine_tune_vars)\n",
        "    optimizer.apply_gradients(zip(gradients, fine_tune_vars))\n",
        "\n",
        "  return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM6tMEEk1wj-"
      },
      "source": [
        "## Begin training\n",
        "\n",
        "We will now start the training loop with the function we authored above in graph mode using 100 batches with 4 examples in each batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pw6iWuy1XSp"
      },
      "outputs": [],
      "source": [
        "num_batch = 100\n",
        "batch_size = 4\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.008, momentum = 0.9)\n",
        "\n",
        "for i in tqdm(range(num_batch)):\n",
        "  values = [0, 1, 2, 3, 4]\n",
        "  random.shuffle(values)\n",
        "  keys = values[0:batch_size]\n",
        "\n",
        "  images = [train_image_tensors[j] for j in keys]\n",
        "  labels = [class_label_tensors[k] for k in keys]\n",
        "  boxes = [bounding_box_tensors[l] for l in keys]\n",
        "\n",
        "  loss = model_train_loop(images, boxes, labels, resnet_model, optimizer, fine_tune_vars)\n",
        "\n",
        "  if i % 10 == 0:\n",
        "        print('batch ' + str(i) + ' of ' + str(num_batch)\n",
        "        + ', loss=' +  str(loss.numpy()), flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33tLLh0cpCHB"
      },
      "source": [
        "# Run inference with the trained model\n",
        "\n",
        "Now we can load in our test data from the test_images directory containing around 50 unseen images of rubber duckies for the model to predict upon. After that, we run a prediction loop where we save the classified images within the ./results directory for further inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhn6c0SgQVVU"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./results/\n",
        "\n",
        "test_image_dir = \"/content/models/research/object_detection/test_images/ducky/test/\"\n",
        "test_images = []\n",
        "for i in range(1, 50):\n",
        "  image_path = os.path.join(test_image_dir, 'out' + str(i) + '.jpg')\n",
        "  test_images.append(imread(image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu1MQwn26zg1"
      },
      "outputs": [],
      "source": [
        "results_dir = \"./results\"\n",
        "os.makedirs(results_dir)\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "  test_image_tensor = tf.expand_dims(tf.convert_to_tensor(test_images[i], dtype='float32'), axis=0)\n",
        "  preprocessed_image, shape = resnet_model.preprocess(test_image_tensor)\n",
        "\n",
        "  predictions = resnet_model.predict(preprocessed_image, shape)\n",
        "  final = resnet_model.postprocess(predictions, shape)\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      test_images[i],\n",
        "      final['detection_boxes'][0].numpy(),\n",
        "      final['detection_classes'][0].numpy().astype('int32') + 1,\n",
        "      final['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "\n",
        "  plt.imsave(os.path.join(results_dir, \"frame_\" + str(i) + \".jpg\"), test_images[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U27VaGL-qDCv"
      },
      "source": [
        "# View final result\n",
        "\n",
        "Finally, we can take the images with detections from before and join them together to create a gif to easily view all results in one animation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgMKrtzq8SSR"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "filenames = [\"frame_\" + str(i) + \".jpg\" for i in range(len(test_images))]\n",
        "gif_path = os.path.join(results_dir, \"ducky.gif\")\n",
        "\n",
        "for filename in filenames:\n",
        "  images.append(imageio.imread(os.path.join(results_dir, filename)))\n",
        "\n",
        "imageio.mimsave(gif_path, images, fps=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62naUK2-qnm2"
      },
      "source": [
        "Please navigate and click on the 'Files' pane on the left and double click on the 'results' folder where you will find the 'ducky.gif'. Clicking this will open a preview of the file on the right. Note this make take a minute or two to load, but trust me it will be worth while to see the final result!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
